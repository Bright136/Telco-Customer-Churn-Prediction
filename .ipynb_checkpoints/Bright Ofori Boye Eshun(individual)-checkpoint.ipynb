{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de54776e",
   "metadata": {},
   "source": [
    "\n",
    "# Training a SDGRegressor model to predict prices of houses.\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "    <li><a href=\"#Data Preparation\">Data Preparation</a>\n",
    "       <ul>\n",
    "           <li><a href=\"#Read Data\">Read Data</a></li>\n",
    "           <li><a href=\"#Clean Data\">Clean Data</a></li>\n",
    "           <li><a href=\"#Feature Engineering\">Feature Engineering</a></li>\n",
    "           <li><a href=\"#Feature Scaling\">Feature Scaling</a></li>\n",
    "       </ul>\n",
    "    <li><a href=\"#Model Training\">Model Training</a>\n",
    "    <li><a href=\"#Model Tuning\">Model Tuning</a></li>\n",
    "    <li><a href=\"#Model Testing\">Model Testing</a></li>\n",
    "       <ul>\n",
    "           <li><a href=\"#Load Model\">Load Model</a></li>\n",
    "           <li><a href=\"#Predict Values\">Predict Values</a></li>\n",
    "           <li><a href=\"#Evaluate Model\">Evaluate Model</a></li>\n",
    "       </ul>\n",
    "    <li><a href=\"#Compare Models\">Compare Models</a></li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b101e442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa3f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69290d01",
   "metadata": {},
   "source": [
    "<a id='Data Preparation'></a>\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f9643",
   "metadata": {},
   "source": [
    "<a id='Read Data'></a>\n",
    "### Read Data\n",
    "In this section:\n",
    ">- we will read and split the data into train dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9703398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d02e4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check fot null values\n",
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd88d20",
   "metadata": {},
   "source": [
    ">- There are 207 missing values in the total_bedrooms columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67de826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display stats on the housing data \n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c4556",
   "metadata": {},
   "source": [
    "#### split data into training  and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787730ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split data into 80% train and 20% test\n",
    "train, test = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c50f874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 10) (4128, 10)\n",
      "test: 20.0%, train: 80.0%\n"
     ]
    }
   ],
   "source": [
    "# confirm the split percentages\n",
    "train_percent = (train.shape[0]/housing.shape[0]) * 100\n",
    "test_percent = 100 - train_percent\n",
    "print(train.shape, test.shape)\n",
    "print(f'test: {test_percent}%, train: {train_percent}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b62157",
   "metadata": {},
   "source": [
    "<a id='Clean Data'></a>\n",
    "### Clean Data\n",
    "In this section:\n",
    ">- we will handle the missing values in the median_house_columns.\n",
    ">- we will also handle categorical columns since machine learning works best with numberical values_we have to transform the text values to numerical values.\n",
    ">- we will chose the best methods to achieve the above tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d547d6b7",
   "metadata": {},
   "source": [
    "#### Handling missing values in the numerical columns\n",
    "Note: This is a demonstration of how the missing data will be replaced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adbbf4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             float64\n",
      "latitude              float64\n",
      "housing_median_age    float64\n",
      "total_rooms           float64\n",
      "total_bedrooms        float64\n",
      "population            float64\n",
      "households            float64\n",
      "median_income         float64\n",
      "median_house_value    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# create a SimpleInputer instance to replace the missing values in the numerical columns with the columns'  median  \n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# drop categorical columns from training dataset\n",
    "train_numerical_columns = train.drop('ocean_proximity', axis=1)\n",
    "print(train_numerical_columns.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "408cbe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1703e+02,  3.2710e+01,  3.3000e+01, ...,  6.2300e+02,\n",
       "         3.2596e+00,  1.0300e+05],\n",
       "       [-1.1816e+02,  3.3770e+01,  4.9000e+01, ...,  7.5600e+02,\n",
       "         3.8125e+00,  3.8210e+05],\n",
       "       [-1.2048e+02,  3.4660e+01,  4.0000e+00, ...,  3.3600e+02,\n",
       "         4.1563e+00,  1.7260e+05],\n",
       "       ...,\n",
       "       [-1.1838e+02,  3.4030e+01,  3.6000e+01, ...,  5.2700e+02,\n",
       "         2.9344e+00,  2.2210e+05],\n",
       "       [-1.2196e+02,  3.7580e+01,  1.5000e+01, ...,  5.5900e+02,\n",
       "         5.7192e+00,  2.8350e+05],\n",
       "       [-1.2242e+02,  3.7770e+01,  5.2000e+01, ...,  1.2420e+03,\n",
       "         2.5755e+00,  3.2500e+05]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transformed = imputer.fit_transform(train_numerical_columns)\n",
    "train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a22359",
   "metadata": {},
   "source": [
    ">- This is array of how the numerical columns of the data would like "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c82b8",
   "metadata": {},
   "source": [
    "#### Handling Categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e66b3b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEAR OCEAN', 'INLAND', '<1H OCEAN', 'NEAR BAY', 'ISLAND'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first let select the categorical columns from the train dataset\n",
    "train_categircal_columns = train[['ocean_proximity']]\n",
    "train_categircal_columns['ocean_proximity'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cce695",
   "metadata": {},
   "source": [
    ">- There are only 5 unique categories in the ocean_proximity columnn hence the OneHotEncoder approach will be used to handle the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b88e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# create a OneHotEncoder instance to handle the categorcal columns \n",
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "# fit and transform the categorical data\n",
    "train_cat_encoder = cat_encoder.fit_transform(train_categircal_columns)\n",
    "train_cat_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c12d5",
   "metadata": {},
   "source": [
    ">- This creates a sparse array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d059c33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets display the sparse array in a numpy array format\n",
    "train_cat_encoder.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed34f9f",
   "metadata": {},
   "source": [
    "<a id='Feature Engineering'></a>\n",
    "### Feature Engineering\n",
    "In this section:\n",
    ">- we will choose and create new features which will help us improve the model will train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8defe500",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['room_per_household'] = train['total_rooms']/ train['households']\n",
    "train['bedrooms_per_rooms'] = train['total_bedrooms']/train['total_rooms']\n",
    "train['population_per_household'] = train['population']/train['households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d6a6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "median_house_value          1.000000\n",
       "median_income               0.690647\n",
       "room_per_household          0.158485\n",
       "total_rooms                 0.133989\n",
       "housing_median_age          0.103706\n",
       "households                  0.063714\n",
       "total_bedrooms              0.047980\n",
       "population_per_household   -0.022030\n",
       "population                 -0.026032\n",
       "longitude                  -0.046349\n",
       "latitude                   -0.142983\n",
       "bedrooms_per_rooms         -0.257419\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444f68b",
   "metadata": {},
   "source": [
    ">- One of the created feature **room_per_household**  has a better correlation compared to some old features}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4081a",
   "metadata": {},
   "source": [
    "<a id='Feature Scaling'></a>\n",
    "### Feature Scaling\n",
    "In this section \n",
    ">- We will check the range_the max and min values in the columns and see how best we can standardize them\n",
    ">- we will also create a pipeline with the selected approaches in the Clean Data section to handle missing values and text values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7969c357",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>room_per_household</th>\n",
       "      <th>bedrooms_per_rooms</th>\n",
       "      <th>population_per_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14196</th>\n",
       "      <td>-117.03</td>\n",
       "      <td>32.71</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3126.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>3.2596</td>\n",
       "      <td>5.017657</td>\n",
       "      <td>0.200576</td>\n",
       "      <td>3.691814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>-118.16</td>\n",
       "      <td>33.77</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3382.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>3.8125</td>\n",
       "      <td>4.473545</td>\n",
       "      <td>0.232703</td>\n",
       "      <td>1.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17445</th>\n",
       "      <td>-120.48</td>\n",
       "      <td>34.66</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>4.1563</td>\n",
       "      <td>5.645833</td>\n",
       "      <td>0.174486</td>\n",
       "      <td>2.723214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14265</th>\n",
       "      <td>-117.11</td>\n",
       "      <td>32.69</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>1.9425</td>\n",
       "      <td>4.002817</td>\n",
       "      <td>0.258269</td>\n",
       "      <td>3.994366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>-119.80</td>\n",
       "      <td>36.78</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2382.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.5542</td>\n",
       "      <td>6.268421</td>\n",
       "      <td>0.180940</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>-117.96</td>\n",
       "      <td>33.78</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>6.3700</td>\n",
       "      <td>6.129032</td>\n",
       "      <td>0.151128</td>\n",
       "      <td>3.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>-117.43</td>\n",
       "      <td>34.02</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>3.0500</td>\n",
       "      <td>6.868597</td>\n",
       "      <td>0.184825</td>\n",
       "      <td>3.904232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>-118.38</td>\n",
       "      <td>34.03</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2101.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>2.9344</td>\n",
       "      <td>3.986717</td>\n",
       "      <td>0.270823</td>\n",
       "      <td>3.332068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-121.96</td>\n",
       "      <td>37.58</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3575.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>5.7192</td>\n",
       "      <td>6.395349</td>\n",
       "      <td>0.166993</td>\n",
       "      <td>3.178891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>-122.42</td>\n",
       "      <td>37.77</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4226.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>2619.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>2.5755</td>\n",
       "      <td>3.402576</td>\n",
       "      <td>0.311169</td>\n",
       "      <td>2.108696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16512 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "14196    -117.03     32.71                33.0       3126.0           627.0   \n",
       "8267     -118.16     33.77                49.0       3382.0           787.0   \n",
       "17445    -120.48     34.66                 4.0       1897.0           331.0   \n",
       "14265    -117.11     32.69                36.0       1421.0           367.0   \n",
       "2271     -119.80     36.78                43.0       2382.0           431.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "11284    -117.96     33.78                35.0       1330.0           201.0   \n",
       "11964    -117.43     34.02                33.0       3084.0           570.0   \n",
       "5390     -118.38     34.03                36.0       2101.0           569.0   \n",
       "860      -121.96     37.58                15.0       3575.0           597.0   \n",
       "15795    -122.42     37.77                52.0       4226.0          1315.0   \n",
       "\n",
       "       population  households  median_income  room_per_household  \\\n",
       "14196      2300.0       623.0         3.2596            5.017657   \n",
       "8267       1314.0       756.0         3.8125            4.473545   \n",
       "17445       915.0       336.0         4.1563            5.645833   \n",
       "14265      1418.0       355.0         1.9425            4.002817   \n",
       "2271        874.0       380.0         3.5542            6.268421   \n",
       "...           ...         ...            ...                 ...   \n",
       "11284       658.0       217.0         6.3700            6.129032   \n",
       "11964      1753.0       449.0         3.0500            6.868597   \n",
       "5390       1756.0       527.0         2.9344            3.986717   \n",
       "860        1777.0       559.0         5.7192            6.395349   \n",
       "15795      2619.0      1242.0         2.5755            3.402576   \n",
       "\n",
       "       bedrooms_per_rooms  population_per_household  \n",
       "14196            0.200576                  3.691814  \n",
       "8267             0.232703                  1.738095  \n",
       "17445            0.174486                  2.723214  \n",
       "14265            0.258269                  3.994366  \n",
       "2271             0.180940                  2.300000  \n",
       "...                   ...                       ...  \n",
       "11284            0.151128                  3.032258  \n",
       "11964            0.184825                  3.904232  \n",
       "5390             0.270823                  3.332068  \n",
       "860              0.166993                  3.178891  \n",
       "15795            0.311169                  2.108696  \n",
       "\n",
       "[16512 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train['median_house_value'].copy()\n",
    "x_train = train.drop('median_house_value', axis=1)\n",
    "train_num_columns = train.drop(['ocean_proximity', 'median_house_value'], axis=1)\n",
    "train_num_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4b2c8",
   "metadata": {},
   "source": [
    ">- since the ranges for the variuos columns are not uniform they will have to be standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c9dd3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline to handle the numerical columns of the training dataset\n",
    "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy='median')), ('std_scaler', StandardScaler())])\n",
    "\n",
    "# Create a pipeline to handle the numerical columns of the training dataset\n",
    "categorical_encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b4ccaf",
   "metadata": {},
   "source": [
    "#### Create a full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ee7188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "# Separate the columns into categorical and numerical columns\n",
    "numerical_attributes = list(train_num_columns)\n",
    "categorical_attributes = ['ocean_proximity']\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer([('num', num_pipeline, numerical_attributes), ('cat', categorical_encoder, categorical_attributes)])\n",
    "\n",
    "x_train = full_pipeline.fit_transform(x_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723780e",
   "metadata": {},
   "source": [
    "<a id='Model Training'></a>\n",
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668bf7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39f01ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# create an instace for SGDRegressor\n",
    "sdg_reg_1 = SGDRegressor()\n",
    "# train the model with train data \n",
    "sdg_reg_1.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c04f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9eae1739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([180082.4625534 , 287140.89800384, 245588.79305412, ...,\n",
       "       194946.47922533, 281342.22304792, 273424.49163324])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predoictios with model created \n",
    "predictions = sdg_reg_1.predict(x_train)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aaabf99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67826.15311590998"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcualate the root meann squared error to to evealute how the nodel is performing making predictions using the train features\n",
    "mse = mean_squared_error(y_true=y_train,y_pred=predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc85f7c",
   "metadata": {},
   "source": [
    "<a id='Model Tuning'></a>\n",
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d61c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid =[{'loss': ['huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],  'learning_rate': ['optimal', 'invscaling', 'adaptive'],  'tol':[0.001, 0.008]}, \\\n",
    "             {'shuffle': [True], 'loss': ['huber', 'epsilon_insensitive'],  'learning_rate': ['optimal'], \\\n",
    "              'max_iter':[500, 1000], 'penalty':['l2', 'l1', 'elasticnet']}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52ae9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_2 = {\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce2826b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg = SGDRegressor()\n",
    "grid_search = GridSearchCV(sgd_reg,param_grid, scoring='neg_mean_squared_error', cv=10, return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3808924c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDRegressor(),\n",
       "             param_grid={'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]),\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
       "                         'loss': ['squared_loss', 'huber',\n",
       "                                  'epsilon_insensitive'],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet']},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_2 = GridSearchCV(sgd_reg, param_grid_2, scoring='neg_mean_squared_error', cv=10, return_train_score=True)\n",
    "grid_search_2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6689daa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=1e-06, learning_rate='optimal', loss='epsilon_insensitive',\n",
       "             penalty='l1')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ddb046b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDRegressor(),\n",
       "             param_grid=[{'learning_rate': ['optimal', 'invscaling',\n",
       "                                            'adaptive'],\n",
       "                          'loss': ['huber', 'epsilon_insensitive',\n",
       "                                   'squared_epsilon_insensitive'],\n",
       "                          'tol': [0.001, 0.008]},\n",
       "                         {'learning_rate': ['optimal'],\n",
       "                          'loss': ['huber', 'epsilon_insensitive'],\n",
       "                          'max_iter': [500, 1000],\n",
       "                          'penalty': ['l2', 'l1', 'elasticnet'],\n",
       "                          'shuffle': [True]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c147554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(learning_rate='adaptive', loss='epsilon_insensitive', tol=0.008)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00ffacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import pickle \n",
    "filename = 'sgd_reg_housing_model_tuned.pkl'\n",
    "filename_2 = 'sgd_reg_housing_model_original.pkl'\n",
    "\n",
    "\n",
    "# filename = 'forest_housing_model.sav'\n",
    "\n",
    "pickle.dump(grid_search.best_estimator_, open(filename, 'wb'))\n",
    "pickle.dump(sdg_reg_1, open(filename_2, 'wb'))\n",
    "\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da73711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "358e771c",
   "metadata": {},
   "source": [
    "<a id='Model Testing'></a>\n",
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6485b",
   "metadata": {},
   "source": [
    "#### Data Preparation for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b96b0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4128, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ckeck the number of rows and columns in train and test datasets\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a26cdf06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values in the test dataset\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fab866",
   "metadata": {},
   "source": [
    "##### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f2977b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the same features used in the traing of the model\n",
    "test['room_per_household'] = test['total_rooms']/ test['households']\n",
    "test['bedrooms_per_rooms'] = test['total_bedrooms']/test['total_rooms']\n",
    "test['population_per_household'] = test['population']/test['households']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbc9eaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4128, 13)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55960e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['median_house_value'].copy() # create the target label for teh test data\n",
    "x_test = test.drop('median_house_value', axis=1) # create the features for the test data\n",
    "test_num = test.drop(['median_house_value', 'ocean_proximity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ff0b296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4128, 12)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee2d90",
   "metadata": {},
   "source": [
    "##### Clean and Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2867cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same pipeline to clean and scale the features of test data\n",
    "numerical_attribs = list(test_num)\n",
    "categorical_attribs = ['ocean_proximity']\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer([('num', num_pipeline, numerical_attribs), ('cat', categorical_encoder, categorical_attribs)])\n",
    "\n",
    "x_test = full_pipeline.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4224517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4128, 16)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0cf579",
   "metadata": {},
   "source": [
    "<a id='Load Model'></a>\n",
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "393afe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11b27e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('sgd_reg_housing_model_tuned.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee8f01e",
   "metadata": {},
   "source": [
    "<a id='Predict Values'></a>\n",
    "### Predict Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "798047bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122981.26400534, 126769.49373578, 129028.05473276, ...,\n",
       "       144818.50420978, 125961.41475154, 131799.65254161])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c79354",
   "metadata": {},
   "source": [
    "<a id='Evaluate Model'></a>\n",
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5306ce56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133357.4352561383"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true=y_true, y_pred=y_pred) \n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "evaluate_model(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695818ad",
   "metadata": {},
   "source": [
    ">- The tuned version of the model has a higher root mean squared error hence we will i will use the original model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f940ae11",
   "metadata": {},
   "source": [
    "<a id='Comapre Models'></a>\n",
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d999e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestModel:  70030.35065599649 SGDRegressor Model:  69282.40164000388\n"
     ]
    }
   ],
   "source": [
    "rnf_model = pickle.load(open('forest_housing_model.pkl', 'rb')) # load the RandomForestModel\n",
    "rnf_pred = rnf_model.predict(x_test)\n",
    "sdg_model_1 = pickle.load(open('sgd_reg_housing_model_original.pkl', 'rb')) # load the first SGDRegressor model created\n",
    "sgd_pred = sdg_model_1.predict(x_test)\n",
    "print('RandomForestModel: ', evaluate_model(y_test, rnf_pred), 'SGDRegressor Model: ', evaluate_model(y_test, sgd_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4dfca",
   "metadata": {},
   "source": [
    ">- Comparing the two models now the SGDRegressor model achieved a lower root mean squared vlues and hence the preferred one.\n",
    ">- Note the SgdRegressor model was trained several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5fda23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.best_estimator_.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d827d076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133357.4352561383"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "950e8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_test > 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aaa31e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20046    True\n",
       "3024     True\n",
       "15663    True\n",
       "20484    True\n",
       "9814     True\n",
       "         ... \n",
       "15362    True\n",
       "16623    True\n",
       "18086    True\n",
       "2144     True\n",
       "3665     True\n",
       "Name: median_house_value, Length: 4128, dtype: bool"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df284490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
